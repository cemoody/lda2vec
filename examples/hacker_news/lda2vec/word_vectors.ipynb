{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to run the code below unless you've trained your own model. Otherwise, simply download the word vectors from the URL below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-04-17 12:37:26--  https://zenodo.org/record/49902/files/vocab.npy\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.66.202\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.66.202|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81754640 (78M) [application/octet-stream]\n",
      "Saving to: ‘vocab.npy.1’\n",
      "\n",
      "vocab.npy.1         100%[=====================>]  77.97M  2.63MB/s   in 26s    \n",
      "\n",
      "2016-04-17 12:38:00 (2.95 MB/s) - ‘vocab.npy.1’ saved [81754640/81754640]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/49902/files/vocab.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-04-17 12:38:40--  https://zenodo.org/record/49902/files/word_vectors.npy\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.66.202\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.66.202|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 116273232 (111M) [application/octet-stream]\n",
      "Saving to: ‘word_vectors.npy’\n",
      "\n",
      "word_vectors.npy    100%[=====================>] 110.89M  9.06MB/s   in 36s    \n",
      "\n",
      "2016-04-17 12:39:19 (3.07 MB/s) - ‘word_vectors.npy’ saved [116273232/116273232]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/49902/files/word_vectors.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from lda2vec_model import LDA2Vec\n",
    "#from chainer import serializers\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import pickle\n",
    "#\n",
    "#features = pd.read_pickle(\"../data/features.pd\")\n",
    "#vocab = np.load(\"../data/vocab\")\n",
    "#npz = np.load(open('topics.story.pyldavis.npz', 'r'))\n",
    "#dat = {k: v for (k, v) in npz.iteritems()}\n",
    "#vocab = dat['vocab'].tolist()\n",
    "#dat = np.load(\"../data/data.npz\")\n",
    "#n_stories = features.story_id_codes.max() + 1\n",
    "#n_units = 256\n",
    "#n_vocab = dat['flattened'].max() + 1\n",
    "#model = LDA2Vec(n_stories=n_stories, n_story_topics=40,\n",
    "#                n_authors=5664, n_author_topics=20,\n",
    "#                n_units=n_units, n_vocab=n_vocab, counts=np.zeros(n_vocab),\n",
    "#                n_samples=15)\n",
    "#serializers.load_hdf5(\"lda2vec.hdf5\", model)\n",
    "#np.save(\"word_vectors\", model.sampler.W.data)\n",
    "#np.save(\"vocab\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "word_vectors_raw = np.load(\"word_vectors.npy\")\n",
    "vocab = np.load(\"vocab.npy\").tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 Normalize the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_vectors = word_vectors_raw / np.linalg.norm(word_vectors_raw, axis=-1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vector(token):\n",
    "    index = vocab.index(token)\n",
    "    return word_vectors[index, :].copy()\n",
    "\n",
    "def most_similar(token, n=20):\n",
    "    word_vector = get_vector(token)\n",
    "    similarities = np.dot(word_vectors, word_vector)\n",
    "    top = np.argsort(similarities)[::-1][:n]\n",
    "    return [vocab[i] for i in top]\n",
    "\n",
    "# This is Levy & Goldberg's 3Cosmul Metric\n",
    "# Based on the Gensim implementation: https://github.com/piskvorky/gensim/blob/master/gensim/models/word2vec.py\n",
    "def cosmul(positives, negatives, topn=20):\n",
    "    positive = [get_vector(p) for p in positives]\n",
    "    negative = [get_vector(n) for n in negatives]\n",
    "    pos_dists = [((1 + np.dot(word_vectors, term)) / 2.) for term in positive]\n",
    "    neg_dists = [((1 + np.dot(word_vectors, term)) / 2.) for term in negative]\n",
    "    dists = np.prod(pos_dists, axis=0) / (np.prod(neg_dists, axis=0) + 1e-6)\n",
    "    idxs = np.argsort(dists)[::-1][:topn]\n",
    "    return [vocab[i] for i in idxs if (vocab[i] not in positives) and (vocab[i] not in negatives)]\n",
    "def most_similar_posneg(positives, negatives, topn=20):\n",
    "    positive = np.sum([get_vector(p) for p in positives], axis=0)\n",
    "    negative = np.sum([get_vector(n) for n in negatives], axis=0)\n",
    "    vector = positive - negative\n",
    "    dists = np.dot(word_vectors, vector)\n",
    "    idxs = np.argsort(dists)[::-1][:topn]\n",
    "    return [vocab[i] for i in idxs if (vocab[i] not in positives) and (vocab[i] not in negatives)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'san francisco',\n",
       " u'seattle',\n",
       " u'sf',\n",
       " u'new york',\n",
       " u'mountain view',\n",
       " u'nyc',\n",
       " u'palo alto',\n",
       " u'new york city',\n",
       " u'austin',\n",
       " u'los angeles',\n",
       " u'atlanta',\n",
       " u'chicago',\n",
       " u'boston',\n",
       " u'soma',\n",
       " u'portland',\n",
       " u'london',\n",
       " u'sunnyvale',\n",
       " u'san jose',\n",
       " u'ny',\n",
       " u'oakland']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('san francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'silicon valley',\n",
       " u'industry',\n",
       " u'u.s.',\n",
       " u'in',\n",
       " u'west',\n",
       " u'agriculture',\n",
       " u'area',\n",
       " u'tech',\n",
       " u'manufacturing',\n",
       " u'city',\n",
       " u'finance',\n",
       " u'valley',\n",
       " u'dc',\n",
       " u'cities',\n",
       " u'america',\n",
       " u'sf',\n",
       " u'new york',\n",
       " u'many areas']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['california', 'technology'], [], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'currencies',\n",
       " u'bitcoin',\n",
       " u'bitcoins',\n",
       " u'gold',\n",
       " u'btc',\n",
       " u'analog',\n",
       " u'commodities',\n",
       " u'trading',\n",
       " u'bitcoin&#x27;s',\n",
       " u'commodity',\n",
       " u'digital goods',\n",
       " u'cryptocurrency',\n",
       " u'mining',\n",
       " u'fiat currency',\n",
       " u'goods',\n",
       " u'fiat',\n",
       " u'coins',\n",
       " u'consumer']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['digital', 'currency'], [], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'vim',\n",
       " u'emacs',\n",
       " u'editor',\n",
       " u'sublime',\n",
       " u'iterm',\n",
       " u'notepad',\n",
       " u'gui',\n",
       " u'vi',\n",
       " u'window manager',\n",
       " u'command line',\n",
       " u'tmux',\n",
       " u'web browser',\n",
       " u'terminals',\n",
       " u'ide',\n",
       " u'editing',\n",
       " u'textmate',\n",
       " u'debugger',\n",
       " u'gvim']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['text editor', 'terminal'], [], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'canada',\n",
       " u'france',\n",
       " u'europe',\n",
       " u'australia',\n",
       " u'uk',\n",
       " u'poland',\n",
       " u'paris',\n",
       " u'hong kong',\n",
       " u'spain',\n",
       " u'usa',\n",
       " u'quebec',\n",
       " u'new zealand',\n",
       " u'japan',\n",
       " u'netherlands',\n",
       " u'italy',\n",
       " u'abroad',\n",
       " u'montreal',\n",
       " u'denmark']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['continental', 'germany'], [], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'apple',\n",
       " u'ms',\n",
       " u'nokia',\n",
       " u'hp',\n",
       " u'google',\n",
       " u'rim',\n",
       " u'adobe',\n",
       " u'samsung',\n",
       " u'msft',\n",
       " u'ibm',\n",
       " u'oracle',\n",
       " u'valve',\n",
       " u'motorola',\n",
       " u'ballmer',\n",
       " u'sony',\n",
       " u'canonical',\n",
       " u'intel',\n",
       " u'cisco',\n",
       " u'yahoo']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['microsoft'], [], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'apple',\n",
       " u'azure',\n",
       " u'ms',\n",
       " u'enterprise',\n",
       " u'google',\n",
       " u'oracle',\n",
       " u'nokia',\n",
       " u'adobe',\n",
       " u'cloud services',\n",
       " u'samsung',\n",
       " u'android',\n",
       " u'ibm',\n",
       " u'carriers',\n",
       " u'intel',\n",
       " u'hardware',\n",
       " u'hp',\n",
       " u'chromeos',\n",
       " u'mobile os']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['microsoft', 'cloud'], [], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queen is several rankings down, so not exactly the same as out of the box word2vec!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'female',\n",
       " u'prussia',\n",
       " u'teen',\n",
       " u'females',\n",
       " u'male',\n",
       " u'queen',\n",
       " u'rapist',\n",
       " u'males',\n",
       " u'young woman',\n",
       " u'girl',\n",
       " u'stairwell',\n",
       " u'white',\n",
       " u'predominately',\n",
       " u'she',\n",
       " u'pronoun',\n",
       " u'accuser',\n",
       " u'celebrity',\n",
       " u'newspaper']"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmul(['king', 'woman'], ['man'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "mark zuckerberg\n",
      "bill gates\n",
      "larry page\n",
      "zuck\n",
      "zuckerberg\n",
      "steve jobs\n",
      "larry ellison\n",
      "jeff bezos\n",
      "sergey brin\n",
      "paul allen\n",
      "richard branson\n",
      "peter thiel\n",
      "mark pincus\n",
      "jack dorsey\n",
      "mark cuban\n",
      "eric schmidt\n",
      "paul graham\n",
      "warren buffet\n",
      "sergey\n",
      "billionaire\n",
      "\n",
      "Cosmul\n",
      "jeff bezos\n",
      "bezos\n",
      "richard branson\n",
      "elon musk\n",
      "elon\n",
      "sells\n",
      "hp\n",
      "dell\n",
      "tesla\n",
      "musk\n",
      "bill gates\n",
      "john carmack\n",
      "amazon&#x27;s\n",
      "warren buffet\n",
      "michael dell\n",
      "prime\n",
      "edison\n",
      "hitachi\n",
      "\n",
      "Traditional Similarity\n",
      "jeff bezos\n",
      "bezos\n",
      "richard branson\n",
      "bill gates\n",
      "amazon&#x27;s\n",
      "sells\n",
      "hp\n",
      "elon musk\n",
      "dell\n",
      "warren buffet\n",
      "prime\n",
      "john carmack\n",
      "paul allen\n",
      "michael dell\n",
      "edison\n",
      "tesla\n",
      "elon\n",
      "ibm\n"
     ]
    }
   ],
   "source": [
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar('mark zuckerberg'))\n",
    "print '\\nCosmul'\n",
    "pos = ['mark zuckerberg', 'amazon']\n",
    "neg = ['facebook']\n",
    "print '\\n'.join(cosmul(pos, neg, topn=20))\n",
    "print '\\nTraditional Similarity'\n",
    "print '\\n'.join(most_similar_posneg(pos, neg, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "hacker news\n",
      "hn\n",
      "hn.\n",
      "front page\n",
      "reddit\n",
      "posted\n",
      "hackernews\n",
      "upvoted\n",
      "comment\n",
      "frontpage\n",
      "commenting\n",
      "comments\n",
      "post\n",
      "slashdot\n",
      "posting\n",
      "quora\n",
      "forum\n",
      "news.yc\n",
      "thread\n",
      "techcrunch\n",
      "\n",
      "Cosmul\n",
      "stackoverflow\n",
      "stack overflow\n",
      "answer\n",
      "answering\n",
      "answers\n",
      "quora\n",
      "questions\n",
      "answered\n",
      "ask\n",
      "asking\n",
      "programming questions\n",
      "obvious question\n",
      "technical questions\n",
      "hn\n",
      "important question\n",
      "first question\n",
      "such questions\n",
      "stack exchange\n",
      "\n",
      "Traditional Similarity\n",
      "answer\n",
      "stackoverflow\n",
      "stack overflow\n",
      "answering\n",
      "quora\n",
      "answers\n",
      "answered\n",
      "ask\n",
      "questions\n",
      "hn\n",
      "asking\n",
      "obvious question\n",
      "first question\n",
      "important question\n",
      "begs\n",
      "real question\n",
      "such questions\n",
      "stack exchange\n"
     ]
    }
   ],
   "source": [
    "pos = ['hacker news', 'question']\n",
    "neg = ['story']\n",
    "\n",
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar(pos[0]))\n",
    "print '\\nCosmul'\n",
    "print '\\n'.join(cosmul(pos, neg, topn=20))\n",
    "print '\\nTraditional Similarity'\n",
    "print '\\n'.join(most_similar_posneg(pos, neg, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "san francisco\n",
      "seattle\n",
      "sf\n",
      "new york\n",
      "mountain view\n",
      "nyc\n",
      "palo alto\n",
      "new york city\n",
      "austin\n",
      "los angeles\n",
      "atlanta\n",
      "chicago\n",
      "boston\n",
      "soma\n",
      "portland\n",
      "london\n",
      "sunnyvale\n",
      "san jose\n",
      "ny\n",
      "oakland\n",
      "\n",
      "Cosmul\n",
      "seattle\n",
      "sf\n",
      "new york\n",
      "mountain view\n",
      "nyc\n",
      "palo alto\n",
      "new york city\n",
      "austin\n",
      "los angeles\n",
      "atlanta\n",
      "chicago\n",
      "boston\n",
      "soma\n",
      "portland\n",
      "london\n",
      "sunnyvale\n",
      "san jose\n",
      "ny\n",
      "oakland\n",
      "\n",
      "Traditional Similarity\n",
      "seattle\n",
      "sf\n",
      "new york\n",
      "mountain view\n",
      "nyc\n",
      "palo alto\n",
      "new york city\n",
      "austin\n",
      "los angeles\n",
      "atlanta\n",
      "chicago\n",
      "boston\n",
      "soma\n",
      "portland\n",
      "london\n",
      "sunnyvale\n",
      "san jose\n",
      "ny\n",
      "oakland\n"
     ]
    }
   ],
   "source": [
    "pos = ['san francisco']\n",
    "neg = []\n",
    "\n",
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar(pos[0]))\n",
    "print '\\nCosmul'\n",
    "print '\\n'.join(cosmul(pos, neg, topn=20))\n",
    "print '\\nTraditional Similarity'\n",
    "print '\\n'.join(most_similar_posneg(pos, neg, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "nlp\n",
      "machine learning\n",
      "natural language processing\n",
      "data mining\n",
      "algorithms\n",
      "computer vision\n",
      "clustering\n",
      "ml\n",
      "analysis\n",
      "image processing\n",
      "hadoop\n",
      "visualization\n",
      "information retrieval\n",
      "classification\n",
      "numerical\n",
      "data analysis\n",
      "algorithm design\n",
      "statistical\n",
      "opencv\n",
      "analytics\n",
      "\n",
      "Cosmul\n",
      "machine learning\n",
      "computer vision\n",
      "natural language processing\n",
      "ai\n",
      "data mining\n",
      "analysis\n",
      "algorithm\n",
      "randomized\n",
      "simulations\n",
      "engine\n",
      "image processing\n",
      "visualization\n",
      "computational\n",
      "statistical\n",
      "information retrieval\n",
      "probabilistic graphical models\n",
      "opencv\n",
      "clustering\n",
      "machine\n",
      "\n",
      "Traditional Similarity\n",
      "machine learning\n",
      "natural language processing\n",
      "computer vision\n",
      "data mining\n",
      "analysis\n",
      "ai\n",
      "algorithm\n",
      "image processing\n",
      "randomized\n",
      "visualization\n",
      "engine\n",
      "clustering\n",
      "simulations\n",
      "information retrieval\n",
      "statistical\n",
      "opencv\n",
      "algorithms\n",
      "computational\n"
     ]
    }
   ],
   "source": [
    "pos = ['nlp', 'image']\n",
    "neg = ['text']\n",
    "\n",
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar(pos[0]))\n",
    "print '\\nCosmul'\n",
    "print '\\n'.join(cosmul(pos, neg, topn=20))\n",
    "print '\\nTraditional Similarity'\n",
    "print '\\n'.join(most_similar_posneg(pos, neg, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "vim\n",
      "emacs\n",
      "vi\n",
      "textmate\n",
      "sublime\n",
      "zsh\n",
      "tmux\n",
      "terminal\n",
      "sublime text\n",
      "eclipse\n",
      "macvim\n",
      "intellij\n",
      "xmonad\n",
      "iterm\n",
      "st2\n",
      "netbeans\n",
      "ide\n",
      "text editor\n",
      "gedit\n",
      "editor\n",
      "\n",
      "Cosmul\n",
      "photoshop\n",
      "typography\n",
      "animations\n",
      "design\n",
      "programming\n",
      "gradients\n",
      "gameplay\n",
      "textures\n",
      "illustrator\n",
      "inkscape\n",
      "fonts\n",
      "colors\n",
      "ides\n",
      "visual\n",
      "graphic design\n",
      "algorithms\n",
      "usability\n",
      "gimp\n",
      "layouts\n",
      "\n",
      "Traditional Similarity\n",
      "photoshop\n",
      "typography\n",
      "animations\n",
      "textures\n",
      "gameplay\n",
      "gradients\n",
      "inkscape\n",
      "design\n",
      "illustrator\n",
      "programming\n",
      "ides\n",
      "fonts\n",
      "colors\n",
      "visual\n",
      "gimp\n",
      "layouts\n",
      "canvas\n",
      "uis\n"
     ]
    }
   ],
   "source": [
    "pos = ['vim', 'graphics']\n",
    "neg = ['terminal']\n",
    "\n",
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar(pos[0]))\n",
    "print '\\nCosmul'\n",
    "print '\\n'.join(cosmul(pos, neg, topn=20))\n",
    "print '\\nTraditional Similarity'\n",
    "print '\\n'.join(most_similar_posneg(pos, neg, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "vegetables\n",
      "meat\n",
      "rice\n",
      "protein\n",
      "eat\n",
      "veggies\n",
      "fruits\n",
      "meats\n",
      "cheese\n",
      "soy\n",
      "pasta\n",
      "veg\n",
      "beans\n",
      "foods\n",
      "cook\n",
      "milk\n",
      "eating\n",
      "grains\n",
      "fresh fruit\n",
      "bread\n",
      "\n",
      "Cosmul\n",
      "tea\n",
      "drinking\n",
      "beer\n",
      "coffee\n",
      "alcohol\n",
      "cup\n",
      "soda\n",
      "milk\n",
      "cups\n",
      "rice\n",
      "vodka\n",
      "drank\n",
      "drinks\n",
      "sugar\n",
      "beans\n",
      "red wine\n",
      "pot\n",
      "wine\n",
      "\n",
      "Traditional Similarity\n",
      "tea\n",
      "drinking\n",
      "beer\n",
      "coffee\n",
      "alcohol\n",
      "cup\n",
      "soda\n",
      "milk\n",
      "rice\n",
      "cups\n",
      "drank\n",
      "drinks\n",
      "vodka\n",
      "sugar\n",
      "beans\n",
      "pot\n",
      "red wine\n",
      "wine\n"
     ]
    }
   ],
   "source": [
    "pos = ['vegetables', 'drink']\n",
    "neg = ['eat']\n",
    "\n",
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar(pos[0]))\n",
    "print '\\nCosmul'\n",
    "print '\\n'.join(cosmul(pos, neg, topn=20))\n",
    "print '\\nTraditional Similarity'\n",
    "print '\\n'.join(most_similar_posneg(pos, neg, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar\n",
      "lda\n",
      "kmeans\n",
      "173\n",
      "classification\n",
      "stdev\n",
      "linear\n",
      "clustering\n",
      "regression\n",
      "g(\n",
      "scala&#62\n",
      "fns\n",
      "f(n\n",
      "haruki murakami\n",
      "f(a\n",
      ".map\n",
      "vec\n",
      "chroma\n",
      "\n",
      "\n",
      "         \n",
      "sqrt\n",
      "cache-control\n"
     ]
    }
   ],
   "source": [
    "pos = ['lda', '']\n",
    "neg = ['']\n",
    "\n",
    "print 'Most similar'\n",
    "print '\\n'.join(most_similar(pos[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
